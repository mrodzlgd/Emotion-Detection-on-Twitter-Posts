{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset only provides the tweet id with the emotion label. This code below extracts the text data for each tweet id.\n",
    "* final dataset is smaller since it seems like some tweets were deleted after the dataset was created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information:\n",
    "\n",
    "Paper: http://knoesis.org/sites/default/files/wenbo_socialcom_2012_0.pdf\n",
    "\n",
    "Data: http://knoesis.org/projects/emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['./data/test.txt','./data/dev.txt','./data/train_1.txt','./data/train_2_1.txt','./data/train_2_10.txt','./data/train_2_2.txt','./data/train_2_3.txt','./data/train_2_4.txt','./data/train_2_5.txt','./data/train_2_6.txt','./data/train_2_7.txt','./data/train_2_8.txt','./data/train_2_9.txt']\n",
    "df = pd.concat([pd.read_csv(item , sep = '\\t' , header = None , names = ['tweet_id','emotion']) for item in filelist], axis=0)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9718024 entries, 0 to 9718023\n",
      "Data columns (total 2 columns):\n",
      "tweet_id    int64\n",
      "emotion     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 148.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep = 'first', inplace = True)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2488982, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2488982 entries, 0 to 2488981\n",
      "Data columns (total 2 columns):\n",
      "tweet_id    int64\n",
      "emotion     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 38.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             706182\n",
       "sadness         616471\n",
       "anger           574170\n",
       "love            301759\n",
       "fear            135154\n",
       "thankfulness    131340\n",
       "surprise         23906\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting by emotion\n",
    "\n",
    "* This will help to run the extract in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616471, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad = df.loc[df.emotion == 'sadness']\n",
    "sad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706182, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joy = df.loc[df.emotion == 'joy']\n",
    "joy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574170, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anger = df.loc[df.emotion == 'anger']\n",
    "anger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135154, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear = df.loc[df.emotion == 'fear']\n",
    "fear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23906, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise = df.loc[df.emotion == 'surprise']\n",
    "surprise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131340, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thankfulness = df.loc[df.emotion == 'thankfulness']\n",
    "thankfulness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301759, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "love = df.loc[df.emotion == 'love']\n",
    "love.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Twitter API\n",
    "\n",
    "* credentials removed since this code is being shared in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that contains the credentials to access Twitter API\n",
    "ACCESS_TOKEN =  ''\n",
    "ACCESS_SECRET = ''\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = ''\n",
    "\n",
    "\n",
    "# Setup access to API\n",
    "def connect_to_twitter_OAuth():\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "# Create API object\n",
    "api = connect_to_twitter_OAuth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get Tweet posts by Tweet ID__\n",
    "\n",
    "Twitter Reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(category,label):\n",
    "    \"\"\"This helper function to download tweet posts based on ID\n",
    "    each request pulls 100 id's, the max amount of request is 450 every 15 minutes\n",
    "    will process 45k id's then will wait 15 mins and will continue.\n",
    "    \n",
    "    Inputs: category->the dataset that contains the tweet ids you want to download\n",
    "            label-> the name of the emotion corresponding to those tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    e = list(category.tweet_id)\n",
    "    data = []\n",
    "    total = len(e)\n",
    "    start = 0\n",
    "    end = 100\n",
    "    counter = 0\n",
    "    e_batch = e[start:end]\n",
    "    st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(st,'- extracting ',label)\n",
    "    while total>0:\n",
    "        status = api.statuses_lookup(e_batch)\n",
    "        count = list(range(0,len(status)))\n",
    "        d_counter1 = len(data)         \n",
    "        for x in count:\n",
    "            post = status[x]\n",
    "            tweet = post._json\n",
    "            data.append({'id': tweet['id'] , 'text': tweet['text']})\n",
    "        d_counter2 = len(data) \n",
    "        delta = d_counter2 - d_counter1\n",
    "        counter += delta\n",
    "        start += 100\n",
    "        end += 100\n",
    "        total -= 100\n",
    "        e_batch = e[start:end]      \n",
    "        #when counter is 45k or more it will stop for 15 mins, then the counter is restarted\n",
    "        if counter >= 45000:\n",
    "            st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print('records so far:', len(data))\n",
    "            #wait 15 mins\n",
    "            st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(st,'- waiting 15 mins for next',label,'batch...')\n",
    "            time.sleep(900)\n",
    "            counter = 0\n",
    "            st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(st,'restarted counter:',counter)\n",
    "    edf = pd.DataFrame(data)\n",
    "    name = './data/'+label+'.csv'\n",
    "    st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(st,'done with',label,'batch.')\n",
    "    edf.to_csv(name)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-06 17:10:18 - extracting  joy\n",
      "records so far: 45028\n",
      "counter = , 45028\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 90081\n",
      "counter = , 45053\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 135092\n",
      "counter = , 45011\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 180127\n",
      "counter = , 45035\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 225167\n",
      "counter = , 45040\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 270198\n",
      "counter = , 45031\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 315230\n",
      "counter = , 45032\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "records so far: 360269\n",
      "counter = , 45039\n",
      "2019-11-06 17:10:18 - waiting 15 mins for next joy batch...\n",
      "restarted counter: 0\n",
      "2019-11-06 17:10:18 done with joy batch.\n"
     ]
    }
   ],
   "source": [
    "get_tweets(joy,'joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-06 20:32:57 - extracting  surprise\n",
      "2019-11-06 20:35:15 done with surprise batch.\n"
     ]
    }
   ],
   "source": [
    "time.sleep(900)\n",
    "get_tweets(surprise,'surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-06 20:50:15 - extracting  thankfulness\n",
      "records so far: 45054\n",
      "2019-11-06 20:57:32 - waiting 15 mins for next thankfulness batch...\n",
      "2019-11-06 21:12:32 restarted counter: 0\n",
      "2019-11-06 21:18:00 done with thankfulness batch.\n"
     ]
    }
   ],
   "source": [
    "time.sleep(900)\n",
    "get_tweets(thankfulness,'thankfulness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-06 21:33:00 - extracting  fear\n",
      "records so far: 45039\n",
      "2019-11-06 21:40:56 - waiting 15 mins for next fear batch...\n",
      "2019-11-06 21:55:56 restarted counter: 0\n",
      "2019-11-06 22:00:41 done with fear batch.\n"
     ]
    }
   ],
   "source": [
    "time.sleep(900)\n",
    "get_tweets(fear,'fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-06 22:35:30 - extracting  love\n",
      "records so far: 45053\n",
      "2019-11-06 22:43:21 - waiting 15 mins for next love batch...\n",
      "2019-11-06 22:58:21 restarted counter: 0\n",
      "records so far: 90056\n",
      "2019-11-06 23:06:08 - waiting 15 mins for next love batch...\n",
      "2019-11-06 23:21:08 restarted counter: 0\n",
      "records so far: 135091\n",
      "2019-11-06 23:28:37 - waiting 15 mins for next love batch...\n",
      "2019-11-06 23:43:37 restarted counter: 0\n",
      "2019-11-06 23:49:20 done with love batch.\n"
     ]
    }
   ],
   "source": [
    "get_tweets(love,'love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-07 01:21:00 - extracting  anger\n",
      "records so far: 45019\n",
      "2019-11-07 01:28:18 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 01:43:18 restarted counter: 0\n",
      "records so far: 90042\n",
      "2019-11-07 01:50:35 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 02:05:35 restarted counter: 0\n",
      "records so far: 135087\n",
      "2019-11-07 02:13:17 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 02:28:17 restarted counter: 0\n",
      "records so far: 180117\n",
      "2019-11-07 02:36:03 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 02:51:03 restarted counter: 0\n",
      "records so far: 225153\n",
      "2019-11-07 02:58:51 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 03:13:51 restarted counter: 0\n",
      "records so far: 270179\n",
      "2019-11-07 03:21:58 - waiting 15 mins for next anger batch...\n",
      "2019-11-07 03:36:58 restarted counter: 0\n",
      "2019-11-07 03:40:40 done with anger batch.\n"
     ]
    }
   ],
   "source": [
    "get_tweets(anger,'anger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-07 14:04:59 - extracting  sadness\n",
      "records so far: 45044\n",
      "2019-11-07 14:13:13 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 14:28:13 restarted counter: 0\n",
      "records so far: 90069\n",
      "2019-11-07 14:35:14 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 14:50:14 restarted counter: 0\n",
      "records so far: 135088\n",
      "2019-11-07 14:57:33 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 15:12:33 restarted counter: 0\n",
      "records so far: 180094\n",
      "2019-11-07 15:19:46 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 15:34:46 restarted counter: 0\n",
      "records so far: 225098\n",
      "2019-11-07 15:42:16 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 15:57:16 restarted counter: 0\n",
      "records so far: 270123\n",
      "2019-11-07 16:05:20 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 16:20:20 restarted counter: 0\n",
      "records so far: 315131\n",
      "2019-11-07 16:28:50 - waiting 15 mins for next sadness batch...\n",
      "2019-11-07 16:43:50 restarted counter: 0\n",
      "2019-11-07 16:46:47 done with sadness batch.\n"
     ]
    }
   ],
   "source": [
    "time.sleep(900)\n",
    "get_tweets(sad,'sadness')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
